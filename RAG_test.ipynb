{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q langchain\n","!pip install -q openai\n","!pip install -q sentence_transformers\n","# !pip install -q spacy\n","!pip install -q chromadb\n","!pip install -q optimum\n","!pip install -q auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu122/\n","!pip install -q gradio\n","!pip install -q accelerate\n","!python -m spacy download ja_core_news_sm"],"metadata":{"id":"13cEFEZtRFfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.document_loaders.csv_loader import CSVLoader\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.text_splitter import SpacyTextSplitter\n","from langchain.vectorstores import Chroma\n","\n","loader = CSVLoader(file_path='./csv_test.csv')\n","loader = CSVLoader(file_path='csv_test.csv',\n","                   source_column='詳細',\n","                   metadata_columns=['件名'],\n","                   encoding='CP932',\n","                   csv_args={\"delimiter\": ','})\n","documents = loader.load()\n","\n","text_splitter = SpacyTextSplitter(\n","    chunk_size=300,\n","    pipeline=\"ja_core_news_sm\"\n",")\n","splitted_documents = text_splitter.split_documents(documents)\n","\n","embeddings = HuggingFaceEmbeddings(model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\")\n","\n","database = Chroma(\n","    persist_directory=\"./.data_csv\",\n","    embedding_function=embeddings\n",")\n","\n","database.add_documents(\n","    splitted_documents,\n",")\n","\n","print(\"データベースの作成が完了しました。\")"],"metadata":{"id":"8dy0nzxqRMio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["API_KEY = \"\""],"metadata":{"id":"BiRENX7xmEO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFacePipeline\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from langchain.chat_models import ChatOpenAI\n","import gradio as gr\n","\n","with gr.Blocks() as demo:\n","\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox(show_label=False, placeholder=\"業務について分からないことがあれば聞いてください\")\n","    clear = gr.ClearButton([msg, chatbot])\n","\n","    llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-4-1106-preview\", temperature=0)\n","\n","    retriever = database.as_retriever()\n","\n","    qa = RetrievalQA.from_llm(\n","        llm=llm,\n","        retriever=retriever,\n","        return_source_documents=True\n","    )\n","\n","    def chat(prompt, message_history):\n","        global qa\n","\n","        result = qa(prompt)[\"result\"]\n","\n","        message_history.append((prompt, result))\n","\n","        return \"\", message_history\n","\n","    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n","\n","demo.queue()\n","demo.launch()"],"metadata":{"id":"0vb9OaIqRQbR"},"execution_count":null,"outputs":[]}]}